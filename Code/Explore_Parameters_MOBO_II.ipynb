{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3607d54-ec43-464d-ae35-253dc26a359c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np # lower than numpy 2.0\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "import umap.umap_ as umap # from umap-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c6a7ed",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4823b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_dic_to_df(results):\n",
    "    \"\"\"\n",
    "    converts the results dictionary into a data frame containing medium components (unless they are fixed or sodium), \n",
    "    growth rate, medium cost, production rate and if the medium composition is Pareto optimal.\n",
    "\n",
    "    PARAMETERS\n",
    "    * results - dictionary - output of media_BayesOpt()\n",
    "\n",
    "    RETURNS\n",
    "    * results_df - dataframe - \n",
    "    \n",
    "    \"\"\"\n",
    "    # Convert result dictionary to a dataframe - columns are media components, growth, costs, growth per cost, rows are iterations\n",
    "    results_df = pd.DataFrame.from_dict(results[\"medium list\"])\n",
    "    \n",
    "    # Remove the columns (medium components) for which the upper and lower bound are the same\n",
    "    bounds = results[\"medium component bounds\"]\n",
    "    for component, bound in bounds.items():\n",
    "        if bound[0] == bound[1]:  # Check if the bounds are fixed\n",
    "            results_df.drop(columns=component, inplace=True)  # Drop the column from the dataframe\n",
    "    \n",
    "    # drop sodium\n",
    "    results_df.drop(columns = \"EX_na1_e\", inplace = True)\n",
    "\n",
    "    # Add two new columns with growth rates and cost \n",
    "    results_df[\"growth rate\"] = results[\"growth rate tensors\"]\n",
    "    results_df[\"medium cost\"] = results[\"cost tensors\"]\n",
    "    results_df[\"production rate\"] = results[\"production tensors\"]\n",
    "\n",
    "    # Extract data from results (growth rate, medium costs, and if a sample is Pareto optimal)\n",
    "    results_df[\"is pareto\"] = results[\"is pareto\"]\n",
    "    \n",
    "    return(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dca63b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_results(results, results_df, MetModel, initial_medium):\n",
    "    \"\"\"\n",
    "    Classifies all medium compositions based on how they perform compared to the baseline medium\n",
    "    with respect to cost, growth rate, and production rate.\n",
    "\n",
    "    PARAMETERS\n",
    "    * results - dictionary - output of media_BayesOpt()\n",
    "    * results_df - dataframe - output of results_dic_to_df()\n",
    "    * initial_medium - dictionary - Medium for initial simulation\n",
    "    * MetModel - cobra model - Metabolic model for simulation & used for optimisation\n",
    "    * figname - string - name under which to save the figure\n",
    "\n",
    "    RETURNS\n",
    "    * results_df - dataframe - original dataframe with new column containing performance class\n",
    "\n",
    "    \"\"\"\n",
    "    if results[\"optimisation objective\"] == \"growth-production-cost\":\n",
    "        # Set the initial medium as medium in the model\n",
    "        MetModel.medium = initial_medium\n",
    "        MetModel.objective = results[\"model objective\"]\n",
    "\n",
    "        # Run optimization\n",
    "        solution = MetModel.optimize()\n",
    "        initial_growth_rate = solution.fluxes[results[\"biomass objective\"]]\n",
    "        initial_cost = calc_cost_tot(results[\"medium component costs\"], initial_medium)[0].cpu().numpy()\n",
    "        initial_production_rate = solution.fluxes[results[\"production objective\"]]\n",
    "\n",
    "        # Upper bound of biomass flux is the max. growth rate\n",
    "        max_growth = MetModel.reactions.get_by_id(results[\"biomass objective\"]).bounds[1]        \n",
    "\n",
    "        # Define performance categories\n",
    "        factors = [\"cheaper optimal growth with super-opt production\", # 0\n",
    "                   \"costlier optimal growth with super-opt production\", # 1\n",
    "                   \"cheaper optimal growth with sub-opt production\", # 2\n",
    "                   \"costlier optimal growth with sub-opt production\", # 3\n",
    "                   \"sub-opt non-zero growth with super-opt production\", # 4\n",
    "                   \"production without growth\", # 5\n",
    "                   \"no growth and no production\" # 6 \"other\"\n",
    "                   ]\n",
    "\n",
    "        # Add a new column to store performance classifications\n",
    "        results_df[\"performance\"] = \"\"\n",
    "\n",
    "        # Loop over each row and categorize based on growth rate and production rate\n",
    "        for index, row in results_df.iterrows():\n",
    "            growth_rate = row[\"growth rate\"]\n",
    "            production_rate = row[\"production rate\"]\n",
    "            cost = row[\"medium cost\"]\n",
    "\n",
    "            if growth_rate == 0 and production_rate != 0:\n",
    "                performance = factors[5] # \"production without growth\" or \"\" to exclude\n",
    "            elif growth_rate >= max_growth and production_rate <= initial_production_rate and cost < initial_cost:\n",
    "                performance = factors[2] # \"cheaper optimal growth with sub-opt production\"\n",
    "            elif growth_rate >= max_growth and production_rate <= initial_production_rate and cost >= initial_cost:\n",
    "                performance = factors[3] # \"costlier optimal growth with sub-opt production\"\n",
    "            elif growth_rate >= max_growth and production_rate > initial_production_rate and cost < initial_cost:\n",
    "                performance = factors[0] # \"cheaper optimal growth with sub-opt production\"\n",
    "            elif growth_rate >= max_growth and production_rate > initial_production_rate and cost >= initial_cost:\n",
    "                performance = factors[1] # \"costlier optimal growth with super-opt production\"\n",
    "            elif growth_rate < max_growth and production_rate > initial_production_rate:\n",
    "                performance = factors[4] # \"sub-opt nonzero growth with super-opt production\"\n",
    "            else: \n",
    "                performance = factors[6] # \"no growth and no production\" = \"other\"\n",
    "\n",
    "            # Assign the performance category to the dataframe\n",
    "            results_df.at[index, \"performance\"] = performance\n",
    "\n",
    "        # Convert the `performance` column to a categorical type\n",
    "        results_df[\"performance\"] = pd.Categorical(results_df[\"performance\"], \n",
    "                                                   categories = factors, ordered = True)\n",
    "        \n",
    "        # Count the occurrences of each performance category\n",
    "        category_counts = results_df[\"performance\"].value_counts()\n",
    "        # print(\"Category Counts:\\n\", category_counts)\n",
    "    \n",
    "    return(results_df, category_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ab0ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_results_2(results, results_df, MetModel, initial_medium):\n",
    "    \"\"\"\n",
    "    Classifies all medium compositions based on how they perform compared to the baseline medium\n",
    "    with respect to cost, growth rate, and production rate.\n",
    "\n",
    "    PARAMETERS\n",
    "    * results - dictionary - output of media_BayesOpt()\n",
    "    * results_df - dataframe - output of results_dic_to_df()\n",
    "    * initial_medium - dictionary - Medium for initial simulation\n",
    "    * MetModel - cobra model - Metabolic model for simulation & used for optimisation\n",
    "    * figname - string - name under which to save the figure\n",
    "\n",
    "    RETURNS\n",
    "    * results_df - dataframe - original dataframe with new column containing performance class\n",
    "\n",
    "    \"\"\"\n",
    "    if results[\"optimisation objective\"] == \"growth-production-cost\":\n",
    "        # Set the initial medium as medium in the model\n",
    "        MetModel.medium = initial_medium\n",
    "        MetModel.objective = results[\"model objective\"]\n",
    "\n",
    "        # Run optimization\n",
    "        solution = MetModel.optimize()\n",
    "        initial_growth_rate = solution.fluxes[results[\"biomass objective\"]]\n",
    "        initial_cost = calc_cost_tot(results[\"medium component costs\"], initial_medium)[0].cpu().numpy()\n",
    "        initial_production_rate = solution.fluxes[results[\"production objective\"]]\n",
    "\n",
    "        # Upper bound of biomass flux is the max. growth rate\n",
    "        max_growth = MetModel.reactions.get_by_id(results[\"biomass objective\"]).bounds[1]        \n",
    "\n",
    "        # Define performance categories\n",
    "        factors = [\"cheaper optimal growth with super-opt production\", # 0\n",
    "                   \"costlier optimal growth with super-opt production\", # 1\n",
    "                   \"cheaper optimal growth with sub-opt production\", # 2\n",
    "                   \"costlier optimal growth with sub-opt production\", # 3\n",
    "                   \"sub-opt growth with super-opt production\", # 4\n",
    "                   \"sub-opt growth with sub-opt production\", # 5\n",
    "                  \"(almost)no growth and (almost) no production\" # 6 \"other\"\n",
    "                   ]\n",
    "\n",
    "        # Add a new column to store performance classifications\n",
    "        results_df[\"performance\"] = \"\"\n",
    "\n",
    "        # Loop over each row and categorize based on growth rate and production rate\n",
    "        for index, row in results_df.iterrows():\n",
    "            growth_rate = row[\"growth rate\"]\n",
    "            production_rate = row[\"production rate\"]\n",
    "            cost = row[\"medium cost\"]\n",
    "\n",
    "            if growth_rate <= 0.05 and production_rate <= 0.0005:\n",
    "                performance = factors[6] # \"(almost)no growth and (almost) no production\" or \"\" to exclude\n",
    "            elif growth_rate >= max_growth and production_rate <= initial_production_rate and cost < initial_cost:\n",
    "                performance = factors[2] # \"cheaper optimal growth with sub-opt production\"\n",
    "            elif growth_rate >= max_growth and production_rate <= initial_production_rate and cost >= initial_cost:\n",
    "                performance = factors[3] # \"costlier optimal growth with sub-opt production\"\n",
    "            elif growth_rate >= max_growth and production_rate > initial_production_rate and cost < initial_cost:\n",
    "                performance = factors[0] # \"cheaper optimal growth with sub-opt production\"\n",
    "            elif growth_rate >= max_growth and production_rate > initial_production_rate and cost >= initial_cost:\n",
    "                performance = factors[1] # \"costlier optimal growth with super-opt production\"\n",
    "            elif growth_rate < max_growth and production_rate > initial_production_rate:\n",
    "                performance = factors[4] # \"sub-opt growth with sub-opt production\"\n",
    "            else: \n",
    "                performance = factors[5] # \"sub-opt growth with sub-opt production\"\n",
    "\n",
    "            # Assign the performance category to the dataframe\n",
    "            results_df.at[index, \"performance\"] = performance\n",
    "\n",
    "        # Convert the `performance` column to a categorical type\n",
    "        results_df[\"performance\"] = pd.Categorical(results_df[\"performance\"], \n",
    "                                                   categories = factors, ordered = True)\n",
    "        \n",
    "        # Count the occurrences of each performance category\n",
    "        category_counts = results_df[\"performance\"].value_counts()\n",
    "        # print(\"Category Counts:\\n\", category_counts)\n",
    "    \n",
    "    return(results_df, category_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7fd072",
   "metadata": {},
   "source": [
    "## Dimenison Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98953f1b",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212ff254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_plot(results, initial_medium, MetModel, figname):\n",
    "    \"\"\"\n",
    "    Calls classify_results to classify all medium compositions by how they performed compared to inital_medium.\n",
    "    Performs PCA on all medium compositions using only the components as variables.\n",
    "    Plots the result colour-coding the data points by performance class.\n",
    "    Lists the count of each category in legend.\n",
    "    The final plot is saved as png file.\n",
    "    \n",
    "    PARAMETERS\n",
    "    * results - dictionary - output of media_BayesOpt()\n",
    "    * initial_medium - dictionary - Medium for initial simulation\n",
    "    * MetModel - cobra model - Metabolic model for simulation & used for optimisation\n",
    "    * figname - string - name under which to save the figure\n",
    "\n",
    "    RETURNS\n",
    "    -\n",
    "    \n",
    "    \"\"\"\n",
    "    # Convert results dictionary to a dataframe\n",
    "    results_df = results_dic_to_df(results)\n",
    "    \n",
    "    '''Classify according to result quality'''\n",
    "    results_df, category_counts = classify_results(results, results_df, MetModel, initial_medium)\n",
    "    # Create a dictionary mapping performance categories to their counts\n",
    "    category_counts_dict = category_counts.to_dict()\n",
    "\n",
    "    '''Perform and plot PCA using only the medium components (columns starting with \"EX_\")'''\n",
    "    # Select only the columns starting with \"EX_\"\n",
    "    medium_components = results_df.filter(like=\"EX_\", axis=1)\n",
    "\n",
    "    # Standardize the medium components\n",
    "    scaler = StandardScaler()\n",
    "    medium_components_scaled = scaler.fit_transform(medium_components)\n",
    "\n",
    "    # Perform PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_result = pca.fit_transform(medium_components_scaled)\n",
    "\n",
    "    # Add PCA results to the dataframe for plotting\n",
    "    results_df[\"PCA1\"] = pca_result[:, 0]\n",
    "    results_df[\"PCA2\"] = pca_result[:, 1]\n",
    "    # Converts performance values to new labels that include category counts\n",
    "    results_df[\"performance_label\"] = results_df[\"performance\"].apply(\n",
    "        lambda x: f\"{x} ({category_counts_dict.get(x, 0)})\"\n",
    "    )\n",
    "    \n",
    "    # Plot the PCA results\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.scatterplot(\n",
    "        x = \"PCA1\", y = \"PCA2\", \n",
    "        hue = \"performance_label\", \n",
    "        data = results_df, \n",
    "        palette = \"tab10\", \n",
    "        size = \"performance_label\",\n",
    "        sizes = (50, 50),\n",
    "        s=100, edgecolor=\"k\", alpha=0.8\n",
    "    )\n",
    "    plt.title(\"PCA of Medium Components Colored by Performance\", fontsize=14)\n",
    "    plt.xlabel(f\"PC1 ({pca.explained_variance_ratio_[0]*100:.2f}% variance)\", fontsize=12)\n",
    "    plt.ylabel(f\"PC2 ({pca.explained_variance_ratio_[1]*100:.2f}% variance)\", fontsize=12)\n",
    "    plt.grid(True)\n",
    "    #plt.legend(title=\"Performance\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.legend(title = \"Performance (count)\")\n",
    "    plt.tight_layout()\n",
    "    figname = figname + \".png\"\n",
    "    plt.savefig(figname, dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b09876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_plot_2(results, initial_medium, MetModel, figname):\n",
    "    \"\"\"\n",
    "    Calls classify_results to classify all medium compositions by how they performed compared to inital_medium.\n",
    "    Performs PCA on all medium compositions using only the components as variables.\n",
    "    Plots the result colour-coding the data points by performance class.\n",
    "    Lists the count of each category in legend.\n",
    "    The final plot is saved as png file.\n",
    "    \n",
    "    PARAMETERS\n",
    "    * results - dictionary - output of media_BayesOpt()\n",
    "    * initial_medium - dictionary - Medium for initial simulation\n",
    "    * MetModel - cobra model - Metabolic model for simulation & used for optimisation\n",
    "    * figname - string - name under which to save the figure\n",
    "\n",
    "    RETURNS\n",
    "    -\n",
    "    \n",
    "    \"\"\"\n",
    "    # Convert results dictionary to a dataframe\n",
    "    results_df = results_dic_to_df(results)\n",
    "    \n",
    "    '''Classify according to result quality'''\n",
    "    results_df, category_counts = classify_results_2(results, results_df, MetModel, initial_medium)\n",
    "    # Create a dictionary mapping performance categories to their counts\n",
    "    category_counts_dict = category_counts.to_dict()\n",
    "\n",
    "    '''Perform and plot PCA using only the medium components (columns starting with \"EX_\")'''\n",
    "    # Select only the columns starting with \"EX_\"\n",
    "    medium_components = results_df.filter(like=\"EX_\", axis=1)\n",
    "\n",
    "    # Standardize the medium components\n",
    "    scaler = StandardScaler()\n",
    "    medium_components_scaled = scaler.fit_transform(medium_components)\n",
    "\n",
    "    # Perform PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_result = pca.fit_transform(medium_components_scaled)\n",
    "\n",
    "    # Add PCA results to the dataframe for plotting\n",
    "    results_df[\"PCA1\"] = pca_result[:, 0]\n",
    "    results_df[\"PCA2\"] = pca_result[:, 1]\n",
    "    # Converts performance values to new labels that include category counts\n",
    "    results_df[\"performance_label\"] = results_df[\"performance\"].apply(\n",
    "        lambda x: f\"{x} ({category_counts_dict.get(x, 0)})\"\n",
    "    )\n",
    "    \n",
    "    # Plot the PCA results\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.scatterplot(\n",
    "        x = \"PCA1\", y = \"PCA2\", \n",
    "        hue = \"performance_label\", \n",
    "        data = results_df, \n",
    "        palette = \"tab10\", \n",
    "        size = \"performance_label\",\n",
    "        sizes = (50, 50),\n",
    "        s=100, edgecolor=\"k\", alpha=0.8\n",
    "    )\n",
    "    plt.title(\"PCA of Medium Components Colored by Performance\", fontsize=14)\n",
    "    plt.xlabel(f\"PC1 ({pca.explained_variance_ratio_[0]*100:.2f}% variance)\", fontsize=12)\n",
    "    plt.ylabel(f\"PC2 ({pca.explained_variance_ratio_[1]*100:.2f}% variance)\", fontsize=12)\n",
    "    plt.grid(True)\n",
    "    #plt.legend(title=\"Performance\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.legend(title = \"Performance (count)\")\n",
    "    plt.tight_layout()\n",
    "    figname = figname + \".png\"\n",
    "    plt.savefig(figname, dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6986cf8",
   "metadata": {},
   "source": [
    "### t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cea23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_SNE_plot(results, initial_medium, MetModel, figname, perplexity = 20):\n",
    "    \"\"\"\n",
    "    Calls classify_results to classify all medium compositions by how they performed compared to inital_medium.\n",
    "    Performs t-SNE on all medium compositions using only the components as variables.\n",
    "    Plots the result colour-coding the data points by performance class.\n",
    "    The final plot is saved as png file.\n",
    "    \n",
    "    PARAMETERS\n",
    "    * results - dictionary - output of media_BayesOpt()\n",
    "    * initial_medium - dictionary - Medium for initial simulation\n",
    "    * MetModel - cobra model - Metabolic model for simulation & used for optimisation\n",
    "    * figname - string - name under which to save the figure\n",
    "    * perplexity - integer - parameter for t-SNE\n",
    "\n",
    "    RETURNS\n",
    "    -\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert results dictionary to a dataframe\n",
    "    results_df = results_dic_to_df(results)\n",
    "    \n",
    "    '''Classify according to result quality'''\n",
    "    results_df, category_counts = classify_results(results, results_df, MetModel, initial_medium)\n",
    "    # Create a dictionary mapping performance categories to their counts\n",
    "    category_counts_dict = category_counts.to_dict()\n",
    "\n",
    "    '''Perform and plot t-SNE using only the medium components (columns starting with \"EX_\")'''\n",
    "    # Select only the columns starting with \"EX_\"\n",
    "    medium_components = results_df.filter(like=\"EX_\", axis=1)\n",
    "    \n",
    "    tsne = TSNE(n_components = 2,\n",
    "                init = \"random\",\n",
    "                random_state = 42,\n",
    "                perplexity = perplexity,\n",
    "                learning_rate = 200,\n",
    "                max_iter = 300)\n",
    "\n",
    "    tsne_results = tsne.fit_transform(medium_components)\n",
    "    results_df['tsne-2d-one'] = tsne_results[:,0]\n",
    "    results_df['tsne-2d-two'] = tsne_results[:,1]\n",
    "    # Converts performance values to new labels that include category counts\n",
    "    results_df[\"performance_label\"] = results_df[\"performance\"].apply(\n",
    "        lambda x: f\"{x} ({category_counts_dict.get(x, 0)})\"\n",
    "    )\n",
    "\n",
    "    # Plot t-SNE results\n",
    "    plt.figure(figsize=(16,10))\n",
    "    sns.scatterplot(\n",
    "        x = \"tsne-2d-one\", y = \"tsne-2d-two\",\n",
    "        hue = \"performance_label\",\n",
    "        palette = sns.color_palette(\"hls\", 10),\n",
    "        data = results_df,\n",
    "        legend = \"full\",\n",
    "        alpha = 0.9\n",
    "    )\n",
    "\n",
    "    plt.title(\"t-SNE of Medium Components Colored by Performance\", fontsize = 14)\n",
    "    plt.legend(title = \"Performance (count)\")\n",
    "    plt.tight_layout()\n",
    "    figname = figname + \".png\"\n",
    "    plt.savefig(figname, dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82d1067",
   "metadata": {},
   "source": [
    "### UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e493a2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def UMAP_plot(results, initial_medium, MetModel, figname, n_neighbors = 5, min_dist = 0.3):\n",
    "    \"\"\"\n",
    "    Calls classify_results to classify all medium compositions by how they performed compared to inital_medium.\n",
    "    Performs UMAP on all medium compositions using only the components as variables.\n",
    "    Plots the result colour-coding the data points by performance class.\n",
    "    The final plot is saved as png file.\n",
    "    \n",
    "    PARAMETERS\n",
    "    * results - dictionary - output of media_BayesOpt()\n",
    "    * initial_medium - dictionary - Medium for initial simulation\n",
    "    * MetModel - cobra model - Metabolic model for simulation & used for optimisation\n",
    "    * figname - string - name under which to save the figure\n",
    "    * n_neighbours - integer - parameter for UMAP\n",
    "    * min_dist - float - paramter for UMAP\n",
    "\n",
    "    RETURNS\n",
    "    -\n",
    "    \n",
    "    \"\"\"\n",
    "    # Convert results dictionary to a dataframe\n",
    "    results_df = results_dic_to_df(results)\n",
    "    \n",
    "    '''Classify according to result quality'''\n",
    "    results_df, category_counts = classify_results(results, results_df, MetModel, initial_medium)\n",
    "    # Create a dictionary mapping performance categories to their counts\n",
    "    category_counts_dict = category_counts.to_dict()\n",
    "    n_factors = results_df['performance'].nunique()\n",
    "    \n",
    "\n",
    "    '''Perform and plot UMAP using only the medium components (columns starting with \"EX_\")'''\n",
    "    # Select only the columns starting with \"EX_\"\n",
    "    medium_components = results_df.filter(like = \"EX_\", axis=1)\n",
    "\n",
    "    # Standardize the medium components\n",
    "    scaler = StandardScaler()\n",
    "    medium_components_scaled = scaler.fit_transform(medium_components)\n",
    "\n",
    "    # perform UMAP\n",
    "    umap_obj = umap.UMAP(n_neighbors = n_neighbors, min_dist = min_dist, random_state = 42)\n",
    "    embedding = umap_obj.fit_transform(medium_components_scaled)\n",
    "\n",
    "     # Add UMAP embedding to the dataframe\n",
    "    results_df['umap-2d-one'] = embedding[:,0]\n",
    "    results_df['umap-2d-two'] = embedding[:,1]\n",
    "    # Converts performance values to new labels that include category counts\n",
    "    results_df[\"performance_label\"] = results_df[\"performance\"].apply(\n",
    "        lambda x: f\"{x} ({category_counts_dict.get(x, 0)})\"\n",
    "    )\n",
    "\n",
    "    # Plot UMAP results\n",
    "    plt.figure(figsize=(16,10))\n",
    "    sns.scatterplot(\n",
    "        x = \"umap-2d-one\", y = \"umap-2d-two\",\n",
    "        hue = \"performance_label\",\n",
    "        size = \"performance_label\",\n",
    "        sizes = (50, 50),\n",
    "        palette = sns.color_palette(palette = \"tab10\"),\n",
    "        data = results_df,\n",
    "        legend = \"full\",\n",
    "        alpha = 0.9\n",
    "    )\n",
    "\n",
    "    plt.title(\"UMAP of Medium Components Colored by Performance\", fontsize = 14)\n",
    "    plt.legend(title = \"Performance (count)\")\n",
    "    plt.tight_layout()\n",
    "    figname = figname + \".png\"\n",
    "    plt.savefig(figname, dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dde3ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def UMAP_plot_2(results, initial_medium, MetModel, figname, n_neighbors = 5, min_dist = 0.3):\n",
    "    \"\"\"\n",
    "    Calls classify_results to classify all medium compositions by how they performed compared to inital_medium.\n",
    "    Performs UMAP on all medium compositions using only the components as variables.\n",
    "    Plots the result colour-coding the data points by performance class.\n",
    "    The final plot is saved as png file.\n",
    "    \n",
    "    PARAMETERS\n",
    "    * results - dictionary - output of media_BayesOpt()\n",
    "    * initial_medium - dictionary - Medium for initial simulation\n",
    "    * MetModel - cobra model - Metabolic model for simulation & used for optimisation\n",
    "    * figname - string - name under which to save the figure\n",
    "    * n_neighbours - integer - parameter for UMAP\n",
    "    * min_dist - float - paramter for UMAP\n",
    "\n",
    "    RETURNS\n",
    "    -\n",
    "    \n",
    "    \"\"\"\n",
    "    # Convert results dictionary to a dataframe\n",
    "    results_df = results_dic_to_df(results)\n",
    "    \n",
    "    '''Classify according to result quality'''\n",
    "    results_df, category_counts = classify_results_2(results, results_df, MetModel, initial_medium)\n",
    "    # Create a dictionary mapping performance categories to their counts\n",
    "    category_counts_dict = category_counts.to_dict()\n",
    "    n_factors = results_df['performance'].nunique()\n",
    "    \n",
    "\n",
    "    '''Perform and plot UMAP using only the medium components (columns starting with \"EX_\")'''\n",
    "    # Select only the columns starting with \"EX_\"\n",
    "    medium_components = results_df.filter(like = \"EX_\", axis=1)\n",
    "\n",
    "    # Standardize the medium components\n",
    "    scaler = StandardScaler()\n",
    "    medium_components_scaled = scaler.fit_transform(medium_components)\n",
    "\n",
    "    # perform UMAP\n",
    "    umap_obj = umap.UMAP(n_neighbors = n_neighbors, min_dist = min_dist, random_state = 42)\n",
    "    embedding = umap_obj.fit_transform(medium_components_scaled)\n",
    "\n",
    "     # Add UMAP embedding to the dataframe\n",
    "    results_df['umap-2d-one'] = embedding[:,0]\n",
    "    results_df['umap-2d-two'] = embedding[:,1]\n",
    "    # Converts performance values to new labels that include category counts\n",
    "    results_df[\"performance_label\"] = results_df[\"performance\"].apply(\n",
    "        lambda x: f\"{x} ({category_counts_dict.get(x, 0)})\"\n",
    "    )\n",
    "\n",
    "    # Plot UMAP results\n",
    "    plt.figure(figsize=(16,10))\n",
    "    sns.scatterplot(\n",
    "        x = \"umap-2d-one\", y = \"umap-2d-two\",\n",
    "        hue = \"performance_label\",\n",
    "        size = \"performance_label\",\n",
    "        sizes = (50, 50),\n",
    "        palette = sns.color_palette(palette = \"tab10\"),\n",
    "        data = results_df,\n",
    "        legend = \"full\",\n",
    "        alpha = 0.9\n",
    "    )\n",
    "\n",
    "    plt.title(\"UMAP of Medium Components Colored by Performance\", fontsize = 14)\n",
    "    plt.legend(title = \"Performance (count)\")\n",
    "    plt.tight_layout()\n",
    "    figname = figname + \".png\"\n",
    "    plt.savefig(figname, dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f4bf06",
   "metadata": {},
   "source": [
    "## Pairplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595fc672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairplot_best(results, top_percentage = 20, figname = \"pairplot_best\"):\n",
    "    \"\"\"\n",
    "    Subsets the results to the top x percent media compositions with respect to growth per cost.\n",
    "    Produces three different pairplots for all combinations media components, cost, growth-rate and whether a medium is pareto optimal\n",
    "    for those top performing media.\n",
    "    The first shows the distribution of the feature on the x-axis on the diagonal.\n",
    "    In the second one, the dots are colour-coded by growth rate and in the third one by medium cost.\n",
    "    Saves the figures (as png files)\n",
    "\n",
    "    PARAMETERS\n",
    "    * results - dictionary - output of BayesOpt...\n",
    "    * top_percentage - integer - top x percent (growth/cost) to be plotted\n",
    "    * figname - string - name under which to save the figure\n",
    "    \n",
    "    RETURNS\n",
    "    -     \n",
    "    \"\"\"\n",
    "    \n",
    "    # convert result dictionary to a dataframe - columns are media components, growth, costs, growth per cost, rows are iterations\n",
    "    results_df = results_dic_to_df(results)\n",
    "    # create new column with growth per cost\n",
    "    results_df[\"growth per cost\"] = results_df[\"growth rate\"]/results_df[\"medium cost\"]    \n",
    "    # sort by growth/cost\n",
    "    results_df = results_df.sort_values(\"growth per cost\", ascending = False)\n",
    "    # subset to top x percent\n",
    "    cutoff = int(len(results_df)*(top_percentage/100))\n",
    "    results_df_top20 = results_df.iloc[:cutoff]\n",
    "    results_df_top20.drop(columns = \"growth per cost\", inplace = True) # exclude growth per cost\n",
    "    \n",
    "    # plot values for top 20%\n",
    "    # diag_kind = \"kde\" - curve instead of barplots (takes longer)\n",
    "    sns.pairplot(results_df_top20, diag_kind = \"kde\", corner = True)\n",
    "    plt.savefig((figname + \".png\"))\n",
    "    sns.pairplot(results_df_top20, diag_kind = \"kde\", corner = True, hue = \"growth rate\")\n",
    "    plt.savefig((figname + \"hue-growth.png\"))\n",
    "    sns.pairplot(results_df_top20, diag_kind = \"kde\", corner = True, hue = \"medium cost\")\n",
    "    plt.savefig((figname + \"hue-cost.png\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084e1f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairplot_pareto(results, figname = \"pairplot_pareto\"):\n",
    "    \"\"\"\n",
    "    Subsets the results to the media compositions that are Pareto optimal.\n",
    "    Produces three different pairplots for all combinations media components, cost and growth-rate for those Pareto optimal media.\n",
    "    The first shows the distribution of the feature on the x-axis on the diagonal. \n",
    "    In the second one, the dots are colour-coded by growth rate and in the third one by medium cost.\n",
    "    Saves the figures (as png files)\n",
    "\n",
    "    PARAMETERS\n",
    "    * results - dictionary - output of BayesOpt...\n",
    "    * figname - string - name under which to save the figure\n",
    "\n",
    "    RETURNS\n",
    "    -\n",
    "    \"\"\"\n",
    "    # convert result dictionary to a dataframe - columns are media components, growth, costs, growth per cost, rows are iterations\n",
    "    results_df = results_dic_to_df(results)\n",
    "\n",
    "    # Subset to data points on Pareto front\n",
    "    results_pareto_df = results_df[results_df[\"is pareto\"] == True]\n",
    "    results_pareto_df = results_pareto_df.iloc[:, 0:-1]  # Exclude \"is pareto\" column\n",
    "\n",
    "    # Pairplot all columns except for \"is pareto\"\n",
    "    sns.pairplot(results_pareto_df, diag_kind=\"kde\", corner=True)\n",
    "    plt.title(\"Pair Plot for all tested media compositions that are Pareto optimal\")\n",
    "    plt.savefig(figname + \".png\")    \n",
    "    sns.pairplot(results_pareto_df, diag_kind=\"kde\", corner=True, hue=\"growth rate\")\n",
    "    plt.savefig(figname + \"hue-growth.png\")\n",
    "    sns.pairplot(results_pareto_df, diag_kind=\"kde\", corner=True, hue=\"medium cost\")\n",
    "    plt.savefig(figname + \"hue-cost.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bced3b78",
   "metadata": {},
   "source": [
    "## Stripplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9489d34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stripplot_best(results, top_percentage = 20, figname = \"stripplot_best\"):\n",
    "    \"\"\"\n",
    "    Subsets the results to the top x percent media compositions with respect to growth per cost.\n",
    "    Produces a strip plot for all combinations media components for those top performing media.\n",
    "    Saves the figure (as png file)\n",
    "\n",
    "    PARAMETERS\n",
    "    * results - dictionary - output of media_BayesOpt()\n",
    "    * top_percentage - integer - top x percent (growth/cost) to be plotted\n",
    "    * figname - string - name under which to save the figure\n",
    "    \n",
    "    RETURNS\n",
    "    -     \n",
    "    \"\"\"\n",
    "    ###TODO: plot twice and colour according to cost and growth\n",
    "\n",
    "    # convert result dictionary to a dataframe - columns are media components, growth, costs, growth per cost, rows are iterations\n",
    "    results_df = results_dic_to_df(results)\n",
    "    # create new column with growth per cost\n",
    "    results_df[\"growth per cost\"] = results_df[\"growth rate\"]/results_df[\"medium cost\"]    \n",
    "    # sort by growth/cost\n",
    "    results_df = results_df.sort_values(\"growth per cost\", ascending = False)\n",
    "    # subset to top x percent\n",
    "    cutoff = int(len(results_df)*(top_percentage/100))\n",
    "    results_df_top20 = results_df.iloc[:cutoff]\n",
    "    results_df_top20.drop(columns = \"growth per cost\", inplace = True) # exclude growth per cost\n",
    "    \n",
    "    # plot values for top 20%\n",
    "    #sns.stripplot(data = results_df_top20.iloc[:, 0:-1], jitter = False)\n",
    "\n",
    "    # exclude growth rate, cost, etc as the distort the scale\n",
    "    sns.stripplot(data = results_df_top20.iloc[:, 0:-4], jitter = False)\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.title(f\"Strip Plot for the {top_percentage}% of media compositions with the best growth/cost ratio\")\n",
    "    plt.xlabel(\"Component\")\n",
    "    plt.ylabel(\"Upper Bound For Uptake Flux\")\n",
    "    plt.show\n",
    "\n",
    "    figname = figname + \".png\"\n",
    "    plt.savefig(figname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e5e5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stripplot_best_long_medium_cost(results, top_percentage = 20, \n",
    "                                    figname = \"stripplot_long_best_hue-cost\"):\n",
    "    \"\"\"\n",
    "    Produces a stripplot for all media components, cost and growth for the top performing media compositions\n",
    "    The media compositions are binned and colour-coded by medium cost. \n",
    "    For each medium component, a strip for each bin is plotted.\n",
    "    Saves the figure (as png file)\n",
    "    \n",
    "    PARAMETERS\n",
    "    * results - dictionary - output of BayesOpt...\n",
    "    * top_percentage - integer - top x percent (growth/cost) to be plotted\n",
    "    * figname - string - name under which to save the figure\n",
    "\n",
    "    RETURNS\n",
    "    -     \n",
    "    \"\"\"\n",
    "    # convert result dictionary to a dataframe - columns are media components, growth, costs, growth per cost, rows are iterations\n",
    "    results_df = results_dic_to_df(results)\n",
    "    # Calculate growth per cost\n",
    "    results_df[\"growth per cost\"] = results_df[\"growth rate\"] / results_df[\"medium cost\"]\n",
    "    # Sort by growth per cost\n",
    "    results_df = results_df.sort_values(\"growth per cost\", ascending=False)\n",
    "    # subset to top x percent\n",
    "    cutoff = int(len(results_df)*(top_percentage/100))\n",
    "    results_df_top20 = results_df.iloc[:cutoff]\n",
    "    results_df_top20.drop(columns = \"growth per cost\", inplace = True) # exclude growth per cost\n",
    "\n",
    "    # Convert DataFrame from wide to long format, excluding the last three columns\n",
    "    results_df_long = pd.melt(results_df_top20.iloc[:, 0:-3], var_name=\"variable\", value_name=\"value\")\n",
    "\n",
    "    # Repeat the medium cost for each entry in the melted DataFrame\n",
    "    # The number of times to repeat is equal to the number of original columns melted\n",
    "    results_df_long[\"medium cost\"] = np.tile(results_df_top20[\"medium cost\"].values, results_df_long.shape[0] // len(results_df_top20))\n",
    "\n",
    "    # Create a larger figure\n",
    "    plt.figure(figsize=(12, 6))  # Set the width and height in inches\n",
    "    # Title & axes\n",
    "    plt.title(\"Strip Plot Colored by Medium Cost\")\n",
    "    plt.xlabel(\"Component\")\n",
    "    plt.ylabel(\"Upper Bound For Uptake Flux\")\n",
    "    # Plot the stripplot with hue based on medium cost\n",
    "    sns.stripplot(data = results_df_long, x = \"variable\", y = \"value\", hue = \"medium cost\", \n",
    "                  dodge = True, jitter = False)\n",
    "    # Rotate x-axis labels by 90 degrees\n",
    "    plt.xticks(rotation=90)\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "    \n",
    "    # Save the plot\n",
    "    figname = figname + \".png\"\n",
    "    plt.savefig(figname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9626f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stripplot_best_long_growth_rate(results, top_percentage = 20, \n",
    "                                    figname = \"stripplot_long_best_hue-growth\"):\n",
    "    \"\"\"\n",
    "    Produces a stripplot for all media components, cost and growth for the top performing media compositions.\n",
    "    The media compositions are binned and colour-coded by growth rate. \n",
    "    For each medium component, a strip for each bin is plotted.\n",
    "    Saves the figure (as png file)\n",
    "    \n",
    "    PARAMETERS\n",
    "    * results - dictionary - output of BayesOpt...\n",
    "    * top_percentage - integer - top x percent (growth/cost) to be plotted\n",
    "    * figname - string - name under which to save the figure\n",
    "\n",
    "    RETURNS\n",
    "    -     \n",
    "    \"\"\"\n",
    "    # convert result dictionary to a dataframe - columns are media components, growth, costs, growth per cost, rows are iterations\n",
    "    results_df = results_dic_to_df(results)\n",
    "    # Calculate growth per cost\n",
    "    results_df[\"growth per cost\"] = results_df[\"growth rate\"] / results_df[\"medium cost\"]\n",
    "    # Sort by growth per cost\n",
    "    results_df = results_df.sort_values(\"growth per cost\", ascending=False)\n",
    "    # Subset to top x percent\n",
    "    cutoff = int(len(results_df)*(top_percentage/100))\n",
    "    results_df_top20 = results_df.iloc[:cutoff]\n",
    "    results_df_top20.drop(columns = \"growth per cost\", inplace = True) # exclude growth per cost\n",
    "\n",
    "    # Convert DataFrame from wide to long format, excluding the last three columns\n",
    "    results_df_long = pd.melt(results_df_top20.iloc[:, 0:-4], var_name=\"variable\", value_name=\"value\")\n",
    "\n",
    "    # Repeat the growth rate for each entry in the melted DataFrame\n",
    "    # The number of times to repeat is equal to the number of original columns melted\n",
    "    results_df_long[\"growth rate\"] = np.tile(results_df_top20[\"growth rate\"].values, results_df_long.shape[0] // len(results_df_top20))\n",
    "\n",
    "    # Create a larger figure\n",
    "    plt.figure(figsize=(12, 6))  # Set the width and height in inches\n",
    "    # Title & axes\n",
    "    plt.title(\"Strip Plot Colored by Growth Rate\")\n",
    "    plt.xlabel(\"Component\")\n",
    "    plt.ylabel(\"Upper Bound For Uptake Flux\")\n",
    "    # Plot the stripplot with hue based on medium cost\n",
    "    sns.stripplot(data=results_df_long, x=\"variable\", y=\"value\", hue=\"growth rate\", dodge=True, jitter=False)\n",
    "    # Rotate x-axis labels by 90 degrees\n",
    "    plt.xticks(rotation=90)\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "    \n",
    "    # Save the plot\n",
    "    figname = figname + \".png\"\n",
    "    plt.savefig(figname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029745c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stripplot_by_performance(results, initial_medium, MetModel, figname = \"stripplot\"):\n",
    "    \"\"\"\n",
    "    Calls classify_results to classify all medium compositions by how they performed compared to inital_medium.\n",
    "    For each category a stripplot is created containing the strips for each medium component.\n",
    "    The final plots are saved as png files.\n",
    "\n",
    "    PARAMETERS\n",
    "    * results - dictionary - output of media_BayesOpt()\n",
    "    * initial_medium - dictionary - Medium for initial simulation\n",
    "    * MetModel - cobra model - Metabolic model for simulation & used for optimisation\n",
    "    * figname - string - name under which to save the figure\n",
    "\n",
    "    RETURNS\n",
    "    \n",
    "    \"\"\"\n",
    "    # Convert results dictionary to a dataframe\n",
    "    results_df = results_dic_to_df(results)\n",
    "    \n",
    "    '''Classify according to result quality'''\n",
    "    results_df, category_counts = classify_results(results, results_df, MetModel, initial_medium)\n",
    "    # Create a dictionary mapping performance categories to their counts\n",
    "    category_counts_dict = category_counts.to_dict()\n",
    "    \n",
    "    # Ensure performance is a categorical column\n",
    "    performance_categories = results_df[\"performance\"].unique()\n",
    "\n",
    "    '''Plot Stripplot for each performance category'''\n",
    "    for factor in performance_categories:        \n",
    "        # Subset to the rows where performance equals the current factor\n",
    "        subset_df = results_df[results_df[\"performance\"] == factor]\n",
    "        # Select only the columns starting with \"EX_\"; i.e., medium components\n",
    "        medium_components = subset_df.filter(like=\"EX_\", axis=1)\n",
    "        \n",
    "        # Create a new figure for each category\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        sns.stripplot(data=medium_components, jitter=False)\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.title(f\"Stripplot for mediums of category: {factor}\", fontsize=14)\n",
    "        plt.xlabel(\"Component\")\n",
    "        plt.ylabel(\"Upper Bound For Uptake Flux\")\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the figure to a file\n",
    "        file_name = f\"{figname}_{factor}.png\"\n",
    "        plt.savefig(file_name, dpi=300)\n",
    "        print(f\"Saved plot as {file_name}\")\n",
    "        \n",
    "        # Show the figure\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec11cf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stripplot_long_by_performance(\n",
    "    results,\n",
    "    initial_medium,\n",
    "    MetModel,\n",
    "    figname = \"stripplot_long_by-performance\"\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Calls classify_results to classify all medium compositions by how they performed compared to inital_medium.\n",
    "    A long stripplot is created containing the strips for each medium component for each class of medium compositions,\n",
    "    grouped by medium components and colour-coded by performance class.\n",
    "    The final plot containing all stripplots is saved as png file.\n",
    "\n",
    "    PARAMETERS\n",
    "    * results - dictionary - output of media_BayesOpt()\n",
    "    * initial_medium - dictionary - Medium for initial simulation\n",
    "    * MetModel - cobra model - Metabolic model for simulation & used for optimisation\n",
    "    * figname - string - name under which to save the figure\n",
    "\n",
    "    RETURNS\n",
    "    -\n",
    "    \n",
    "    \"\"\"\n",
    "    # Convert results dictionary to a dataframe\n",
    "    results_df = results_dic_to_df(results)\n",
    "    \n",
    "    '''Classify according to result quality'''\n",
    "    results_df, category_counts = classify_results(results, results_df, MetModel, initial_medium)\n",
    "    # Create a dictionary mapping performance categories to their counts\n",
    "    category_counts_dict = category_counts.to_dict()\n",
    "    medium_components = results_df.filter(like = \"EX_\", axis = 1)\n",
    "    medium_components[\"performance_label\"] = results_df[\"performance\"].apply(\n",
    "        lambda x: f\"{x} ({category_counts_dict.get(x, 0)})\"\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Convert DataFrame from wide to long format\n",
    "    results_df_long = pd.melt(\n",
    "        medium_components,\n",
    "        id_vars=[\"performance_label\"],  # Retain the performance column during the melt\n",
    "        var_name=\"variable\",\n",
    "        value_name=\"value\"\n",
    "    )\n",
    "\n",
    "    '''Plot'''\n",
    "    plt.figure(figsize=(12, 6))  # Set the width and height in inches\n",
    "    plt.title(\"Strip Plot Colored by Performance Category\")\n",
    "    plt.xlabel(\"Component\")\n",
    "    plt.ylabel(\"Upper Bound For Uptake Flux\")\n",
    "    # Plot the stripplot with hue based on performance\n",
    "    sns.stripplot(\n",
    "        data = results_df_long,\n",
    "        x = \"variable\",\n",
    "        y = \"value\",\n",
    "        hue = \"performance_label\",\n",
    "        dodge = True,\n",
    "        jitter = False\n",
    "    )\n",
    "    plt.legend(title = \"Performance (count)\")\n",
    "    # Rotate x-axis labels by 90 degrees\n",
    "    plt.xticks(rotation = 90)\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "    \n",
    "    # Save the plot\n",
    "    figname = figname + \".png\"\n",
    "    plt.savefig(figname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ad6bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stripplot_long_by_performance_2(\n",
    "    results,\n",
    "    initial_medium,\n",
    "    MetModel,\n",
    "    figname = \"stripplot_long_by-performance\"\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Calls classify_results to classify all medium compositions by how they performed compared to inital_medium.\n",
    "    A long stripplot is created containing the strips for each medium component for each class of medium compositions,\n",
    "    grouped by medium components and colour-coded by performance class.\n",
    "    The final plot containing all stripplots is saved as png file.\n",
    "\n",
    "    PARAMETERS\n",
    "    * results - dictionary - output of media_BayesOpt()\n",
    "    * initial_medium - dictionary - Medium for initial simulation\n",
    "    * MetModel - cobra model - Metabolic model for simulation & used for optimisation\n",
    "    * figname - string - name under which to save the figure\n",
    "\n",
    "    RETURNS\n",
    "    -\n",
    "    \n",
    "    \"\"\"\n",
    "    # Convert results dictionary to a dataframe\n",
    "    results_df = results_dic_to_df(results)\n",
    "    \n",
    "    '''Classify according to result quality'''\n",
    "    results_df, category_counts = classify_results_2(results, results_df, MetModel, initial_medium)\n",
    "    # Create a dictionary mapping performance categories to their counts\n",
    "    category_counts_dict = category_counts.to_dict()\n",
    "    medium_components = results_df.filter(like = \"EX_\", axis = 1)\n",
    "    medium_components[\"performance_label\"] = results_df[\"performance\"].apply(\n",
    "        lambda x: f\"{x} ({category_counts_dict.get(x, 0)})\"\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Convert DataFrame from wide to long format\n",
    "    results_df_long = pd.melt(\n",
    "        medium_components,\n",
    "        id_vars=[\"performance_label\"],  # Retain the performance column during the melt\n",
    "        var_name=\"variable\",\n",
    "        value_name=\"value\"\n",
    "    )\n",
    "\n",
    "    '''Plot'''\n",
    "    plt.figure(figsize=(12, 6))  # Set the width and height in inches\n",
    "    plt.title(\"Strip Plot Colored by Performance Category\")\n",
    "    plt.xlabel(\"Component\")\n",
    "    plt.ylabel(\"Upper Bound For Uptake Flux\")\n",
    "    # Plot the stripplot with hue based on performance\n",
    "    sns.stripplot(\n",
    "        data = results_df_long,\n",
    "        x = \"variable\",\n",
    "        y = \"value\",\n",
    "        hue = \"performance_label\",\n",
    "        dodge = True,\n",
    "        jitter = False\n",
    "    )\n",
    "    plt.legend(title = \"Performance (count)\")\n",
    "    # Rotate x-axis labels by 90 degrees\n",
    "    plt.xticks(rotation = 90)\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "    \n",
    "    # Save the plot\n",
    "    figname = figname + \".png\"\n",
    "    plt.savefig(figname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5827680a",
   "metadata": {},
   "source": [
    "# Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8f6d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def medium_clustermap(results, initial_medium, MetModel, figname = \"clustermap\"):\n",
    "    \"\"\"\n",
    "    Calls classify_results to classify all medium compositions by how they performed compared to inital_medium. \n",
    "    A heatmap in which all 0-1 normalised medium compositions are hierarchically clustered medium by similarity is produced. \n",
    "    A colour-coded performance-class column is added on the side to allow for the visual identification of grouping by performance. \n",
    "    The final plot is saved as png file.\n",
    "    \n",
    "    PARAMETERS\n",
    "    * results - dictionary - output of media_BayesOpt()\n",
    "    * initial_medium - dictionary - Medium for initial simulation\n",
    "    * MetModel - cobra model - Metabolic model for simulation & used for optimisation\n",
    "    * figname - string - name under which to save the figure\n",
    "\n",
    "    RETURNS\n",
    "    -\n",
    "    \n",
    "    \"\"\"\n",
    "    # Convert results dictionary to a dataframe\n",
    "    results_df = results_dic_to_df(results)\n",
    "    \n",
    "    '''Classify according to result quality'''\n",
    "    results_df, category_counts = classify_results(results, results_df, MetModel, initial_medium)\n",
    "\n",
    "    '''Heatmap'''\n",
    "    # Map performance categories to colors\n",
    "    unique_performance = results_df[\"performance\"].unique()\n",
    "    palette = sns.color_palette(\"Set2\", len(unique_performance))\n",
    "    lut = dict(zip(unique_performance, palette))  # Map each category to a color\n",
    "    row_colors = results_df[\"performance\"].map(lut)\n",
    "\n",
    "    # Select medium components\n",
    "    medium_components = results_df.filter(like=\"EX_\", axis=1)\n",
    "\n",
    "\n",
    "    clustermap = sns.clustermap(\n",
    "        medium_components, \n",
    "        standard_scale = 1, \n",
    "        row_colors=row_colors.to_numpy(),  # Convert to array for alignment\n",
    "        cmap = \"coolwarm\",  # Custom color scale for the heatmap\n",
    "        figsize = (13, 10)\n",
    "    )\n",
    "\n",
    "    # Create a separate legend for the performance categories\n",
    "    legend_patches = [plt.Line2D([0], [0], marker = 'o', color = 'w', markersize = 10,\n",
    "                                 markerfacecolor = color, label = label)\n",
    "                        for label, color in lut.items()]\n",
    "    # Adjust layout and add legend outside the heatmap\n",
    "    plt.subplots_adjust(right = 0.7)  # Make space for the legend\n",
    "    clustermap.ax_heatmap.legend(\n",
    "        handles = legend_patches,\n",
    "        title = \"Performance\",\n",
    "        loc = \"upper left\",\n",
    "        bbox_to_anchor = (1.1, 1),\n",
    "        borderaxespad = 0\n",
    "    )\n",
    "\n",
    "    # Save the plot\n",
    "    figname = figname + \".png\"\n",
    "    plt.savefig(figname)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bayesian-opt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
